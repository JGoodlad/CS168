{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johng\\Anaconda4\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np,sys,os\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.ndimage import imread\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(678)\n",
    "tf.set_random_seed(5678)\n",
    "\n",
    "def tf_relu(x): return tf.nn.relu(x)\n",
    "def d_tf_relu(s): return tf.cast(tf.greater(s,0),dtype=tf.float32)\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def np_sigmoid(x): 1/(1 + np.exp(-1 *x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- make class ---\n",
    "class conlayer_left():\n",
    "    \n",
    "    def __init__(self,ker,in_c,out_c):\n",
    "        self.w = tf.Variable(tf.random_normal([ker,ker,in_c,out_c],stddev=0.05))\n",
    "\n",
    "    def feedforward(self,input,stride=1,dilate=1):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides = [1,stride,stride,1],padding='SAME')\n",
    "        self.layerA = tf_relu(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "class conlayer_right():\n",
    "    \n",
    "    def __init__(self,ker,in_c,out_c):\n",
    "        self.w = tf.Variable(tf.random_normal([ker,ker,in_c,out_c],stddev=0.05))\n",
    "\n",
    "    def feedforward(self,input,stride=1,dilate=1,output=1):\n",
    "        self.input  = input\n",
    "\n",
    "        current_shape_size = input.shape\n",
    "\n",
    "        self.layer = tf.nn.conv2d_transpose(input,self.w,\n",
    "        output_shape=[batch_size] + [int(current_shape_size[1].value*2),int(current_shape_size[2].value*2),int(current_shape_size[3].value/2)],strides=[1,2,2,1],padding='SAME')\n",
    "        self.layerA = tf_relu(self.layer)\n",
    "        return self.layerA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- get data ---\n",
    "data_location = \"./images/\"\n",
    "train_data = []  # create an empty list\n",
    "for dirName, subdirList, fileList in sorted(os.walk(data_location)):\n",
    "    for filename in fileList:\n",
    "        if \".tif\" in filename.lower():  # check whether the file's DICOM\n",
    "            train_data.append(os.path.join(dirName,filename))\n",
    "\n",
    "data_location = \"./masks/\"\n",
    "train_data_gt = []  # create an empty list\n",
    "for dirName, subdirList, fileList in sorted(os.walk(data_location)):\n",
    "    for filename in fileList:\n",
    "        if \".tif\" in filename.lower():  # check whether the file's DICOM\n",
    "            train_data_gt.append(os.path.join(dirName,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johng\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  \n",
      "C:\\Users\\Johng\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n",
      "C:\\Users\\Johng\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  import sys\n",
      "C:\\Users\\Johng\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "train_images = np.zeros(shape=(256,256,256,1))\n",
    "train_labels = np.zeros(shape=(256,256,256,1))\n",
    "\n",
    "# for file_index in range(len(train_data)):\n",
    "for file_index in range(256):\n",
    "    train_images[file_index,:,:]   = np.expand_dims(imresize(imread(train_data[file_index],mode='F',flatten=True),(256,256)),axis=2)\n",
    "    train_labels[file_index,:,:]   = np.expand_dims(imresize(imread(train_data_gt[file_index],mode='F',flatten=True),(256,256)),axis=2)\n",
    "\n",
    "train_images = (train_images - train_images.min()) / (train_images.max() - train_images.min())\n",
    "train_labels = (train_labels - train_labels.min()) / (train_labels.max() - train_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- hyper ---\n",
    "num_epoch = 100\n",
    "init_lr = 0.0001\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- make layer ---\n",
    "# left\n",
    "l1_1 = conlayer_left(3,1,3)\n",
    "l1_2 = conlayer_left(3,3,3)\n",
    "l1_3 = conlayer_left(3,3,3)\n",
    "\n",
    "l2_1 = conlayer_left(3,3,6)\n",
    "l2_2 = conlayer_left(3,6,6)\n",
    "l2_3 = conlayer_left(3,6,6)\n",
    "\n",
    "l3_1 = conlayer_left(3,6,12)\n",
    "l3_2 = conlayer_left(3,12,12)\n",
    "l3_3 = conlayer_left(3,12,12)\n",
    "\n",
    "l4_1 = conlayer_left(3,12,24)\n",
    "l4_2 = conlayer_left(3,24,24)\n",
    "l4_3 = conlayer_left(3,24,24)\n",
    "\n",
    "l5_1 = conlayer_left(3,24,48)\n",
    "l5_2 = conlayer_left(3,48,48)\n",
    "l5_3 = conlayer_left(3,48,24)\n",
    "\n",
    "# right\n",
    "l6_1 = conlayer_right(3,24,48)\n",
    "l6_2 = conlayer_left(3,24,24)\n",
    "l6_3 = conlayer_left(3,24,12)\n",
    "\n",
    "l7_1 = conlayer_right(3,12,24)\n",
    "l7_2 = conlayer_left(3,12,12)\n",
    "l7_3 = conlayer_left(3,12,6)\n",
    "\n",
    "l8_1 = conlayer_right(3,6,12)\n",
    "l8_2 = conlayer_left(3,6,6)\n",
    "l8_3 = conlayer_left(3,6,3)\n",
    "\n",
    "l9_1 = conlayer_right(3,3,6)\n",
    "l9_2 = conlayer_left(3,3,3)\n",
    "l9_3 = conlayer_left(3,3,3)\n",
    "\n",
    "l10_final = conlayer_left(3,3,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- make graph ----\n",
    "x = tf.placeholder(shape=[None,256,256,1],dtype=tf.float32)\n",
    "y = tf.placeholder(shape=[None,256,256,1],dtype=tf.float32)\n",
    "\n",
    "layer1_1 = l1_1.feedforward(x)\n",
    "layer1_2 = l1_2.feedforward(layer1_1)\n",
    "layer1_3 = l1_3.feedforward(layer1_2)\n",
    "\n",
    "layer2_Input = tf.nn.max_pool(layer1_3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "layer2_1 = l2_1.feedforward(layer2_Input)\n",
    "layer2_2 = l2_2.feedforward(layer2_1)\n",
    "layer2_3 = l2_3.feedforward(layer2_2)\n",
    "\n",
    "layer3_Input = tf.nn.max_pool(layer2_3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "layer3_1 = l3_1.feedforward(layer3_Input)\n",
    "layer3_2 = l3_2.feedforward(layer3_1)\n",
    "layer3_3 = l3_3.feedforward(layer3_2)\n",
    "\n",
    "layer4_Input = tf.nn.max_pool(layer3_3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "layer4_1 = l4_1.feedforward(layer4_Input)\n",
    "layer4_2 = l4_2.feedforward(layer4_1)\n",
    "layer4_3 = l4_3.feedforward(layer4_2)\n",
    "\n",
    "layer5_Input = tf.nn.max_pool(layer4_3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "layer5_1 = l5_1.feedforward(layer5_Input)\n",
    "layer5_2 = l5_2.feedforward(layer5_1)\n",
    "layer5_3 = l5_3.feedforward(layer5_2)\n",
    "\n",
    "layer6_Input = tf.concat([layer5_3,layer5_Input],axis=3)\n",
    "layer6_1 = l6_1.feedforward(layer6_Input)\n",
    "layer6_2 = l6_2.feedforward(layer6_1)\n",
    "layer6_3 = l6_3.feedforward(layer6_2)\n",
    "\n",
    "layer7_Input = tf.concat([layer6_3,layer4_Input],axis=3)\n",
    "layer7_1 = l7_1.feedforward(layer7_Input)\n",
    "layer7_2 = l7_2.feedforward(layer7_1)\n",
    "layer7_3 = l7_3.feedforward(layer7_2)\n",
    "\n",
    "layer8_Input = tf.concat([layer7_3,layer3_Input],axis=3)\n",
    "layer8_1 = l8_1.feedforward(layer8_Input)\n",
    "layer8_2 = l8_2.feedforward(layer8_1)\n",
    "layer8_3 = l8_3.feedforward(layer8_2)\n",
    "\n",
    "layer9_Input = tf.concat([layer8_3,layer2_Input],axis=3)\n",
    "layer9_1 = l9_1.feedforward(layer9_Input)\n",
    "layer9_2 = l9_2.feedforward(layer9_1)\n",
    "layer9_3 = l9_3.feedforward(layer9_2)\n",
    "\n",
    "layer10 = l10_final.feedforward(layer9_3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(layer10-y))\n",
    "auto_train = tf.train.AdamOptimizer(learning_rate=init_lr).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iter:  0  Cost:  0.00000000000000066491546375958702\n",
      "-----------------------\n",
      " Iter:  1  Cost:  0.01073344331234693527221679687500\n",
      "-----------------------\n",
      " Iter:  2  Cost:  0.01804143190383911132812500000000\n",
      "-----------------------\n",
      " Iter:  3  Cost:  0.00018669526616577059030532836914\n",
      "-----------------------\n",
      " Iter:  4  Cost:  0.03340850770473480224609375000000\n",
      "-----------------------\n",
      " Iter:  5  Cost:  0.00846075359731912612915039062500\n",
      "-----------------------\n",
      " Iter:  6  Cost:  0.00019950530258938670158386230469\n",
      "-----------------------\n",
      " Iter:  7  Cost:  0.03531992435455322265625000000000\n",
      "-----------------------\n",
      " Iter:  8  Cost:  0.00023265663185156881809234619141\n",
      "-----------------------\n",
      " Iter:  9  Cost:  0.00021990263485349714756011962891\n",
      "-----------------------\n",
      " Iter:  10  Cost:  0.01427919045090675354003906250000\n",
      "-----------------------\n",
      " Iter:  11  Cost:  0.01583514362573623657226562500000\n",
      "-----------------------\n",
      " Iter:  12  Cost:  0.03772583603858947753906250000000\n",
      "-----------------------\n",
      " Iter:  13  Cost:  0.02586865797638893127441406250000\n",
      "-----------------------\n",
      " Iter:  14  Cost:  0.02782638557255268096923828125000\n",
      "-----------------------\n",
      " Iter:  15  Cost:  0.00022369979706127196550369262695\n",
      "-----------------------\n",
      " Iter:  16  Cost:  0.02577876299619674682617187500000\n",
      "-----------------------\n",
      " Iter:  17  Cost:  0.00026781682390719652175903320312\n",
      "-----------------------\n",
      " Iter:  18  Cost:  0.00030363292898982763290405273438\n",
      "-----------------------\n",
      " Iter:  19  Cost:  0.00023915823840070515871047973633\n",
      "-----------------------\n",
      " Iter:  20  Cost:  0.00026034633629024028778076171875\n",
      "-----------------------\n",
      " Iter:  21  Cost:  0.00021050326176919043064117431641\n",
      "-----------------------\n",
      " Iter:  22  Cost:  0.01454940438270568847656250000000\n",
      "-----------------------\n",
      " Iter:  23  Cost:  0.00016242105630226433277130126953\n",
      "-----------------------\n",
      " Iter:  24  Cost:  0.02377568930387496948242187500000\n",
      "-----------------------\n",
      " Iter:  25  Cost:  0.02361753582954406738281250000000\n",
      "-----------------------\n",
      " Iter:  26  Cost:  0.02555940300226211547851562500000\n",
      "-----------------------\n",
      " Iter:  27  Cost:  0.00008019059896469116210937500000\n",
      "-----------------------\n",
      " Iter:  28  Cost:  0.00008415320917265489697456359863\n",
      "-----------------------\n",
      " Iter:  29  Cost:  0.00927302148193120956420898437500\n",
      "-----------------------\n",
      " Iter:  30  Cost:  0.01680856756865978240966796875000\n",
      "-----------------------\n",
      " Iter:  31  Cost:  0.01876771077513694763183593750000\n",
      "-----------------------\n",
      " Iter:  32  Cost:  0.00107288034632802009582519531250\n",
      "-----------------------\n",
      " Iter:  33  Cost:  0.01258723717182874679565429687500\n",
      "-----------------------\n",
      " Iter:  34  Cost:  0.01126033719629049301147460937500\n",
      "-----------------------\n",
      " Iter:  35  Cost:  0.00117316539399325847625732421875\n",
      "-----------------------\n",
      " Iter:  36  Cost:  0.01560945808887481689453125000000\n",
      "-----------------------\n",
      " Iter:  37  Cost:  0.00047998991794884204864501953125\n",
      "-----------------------\n",
      " Iter:  38  Cost:  0.01929998025298118591308593750000\n",
      "-----------------------\n",
      " Iter:  39  Cost:  0.01320099644362926483154296875000\n",
      "-----------------------\n",
      " Iter:  40  Cost:  0.01023304276168346405029296875000\n",
      "-----------------------\n",
      " Iter:  41  Cost:  0.01089881733059883117675781250000\n",
      "-----------------------\n",
      " Iter:  42  Cost:  0.01550905592739582061767578125000\n",
      "-----------------------\n",
      " Iter:  43  Cost:  0.02682073786854743957519531250000\n",
      "-----------------------\n",
      " Iter:  44  Cost:  0.00120302150025963783264160156250\n",
      "-----------------------\n",
      " Iter:  45  Cost:  0.01117886602878570556640625000000\n",
      "-----------------------\n",
      " Iter:  46  Cost:  0.01947914063930511474609375000000\n",
      "-----------------------\n",
      " Iter:  47  Cost:  0.01900222152471542358398437500000\n",
      "-----------------------\n",
      " Iter:  48  Cost:  0.02341296337544918060302734375000\n",
      "-----------------------\n",
      " Iter:  49  Cost:  0.01164749730378389358520507812500\n",
      "-----------------------\n",
      " Iter:  50  Cost:  0.00202542054466903209686279296875\n",
      "-----------------------\n",
      " Iter:  51  Cost:  0.01476557180285453796386718750000\n",
      "-----------------------\n",
      " Iter:  52  Cost:  0.02283520810306072235107421875000\n",
      "-----------------------\n",
      " Iter:  53  Cost:  0.02084715478122234344482421875000\n",
      "-----------------------\n",
      " Iter:  54  Cost:  0.01257199794054031372070312500000\n",
      "-----------------------\n",
      " Iter:  55  Cost:  0.01441859267652034759521484375000\n",
      "-----------------------\n",
      " Iter:  56  Cost:  0.01305570080876350402832031250000\n",
      "-----------------------\n",
      " Iter:  57  Cost:  0.01296223141252994537353515625000\n",
      "-----------------------\n",
      " Iter:  58  Cost:  0.01856720447540283203125000000000\n",
      "-----------------------\n",
      " Iter:  59  Cost:  0.00146345840767025947570800781250\n",
      "-----------------------\n",
      " Iter:  60  Cost:  0.00118123518768697977066040039062\n",
      "-----------------------\n",
      " Iter:  61  Cost:  0.01580142602324485778808593750000\n",
      "-----------------------\n",
      " Iter:  62  Cost:  0.02144255116581916809082031250000\n",
      "-----------------------\n",
      " Iter:  63  Cost:  0.00283078080974519252777099609375\n",
      "-----------------------\n",
      " Iter:  64  Cost:  0.00125284132082015275955200195312\n",
      "-----------------------\n",
      " Iter:  65  Cost:  0.01576365530490875244140625000000\n",
      "-----------------------\n",
      " Iter:  66  Cost:  0.00321353063918650150299072265625\n",
      "-----------------------\n",
      " Iter:  67  Cost:  0.00803126394748687744140625000000\n",
      "-----------------------\n",
      " Iter:  68  Cost:  0.00824799016118049621582031250000\n",
      "-----------------------\n",
      " Iter:  69  Cost:  0.00671611446887254714965820312500\n",
      "-----------------------\n",
      " Iter:  70  Cost:  0.00884100515395402908325195312500\n",
      "-----------------------\n",
      " Iter:  71  Cost:  0.02462158724665641784667968750000\n",
      "-----------------------\n",
      " Iter:  72  Cost:  0.00187404372263699769973754882812\n",
      "-----------------------\n",
      " Iter:  73  Cost:  0.00917705241590738296508789062500\n",
      "-----------------------\n",
      " Iter:  74  Cost:  0.02586048096418380737304687500000\n",
      "-----------------------\n",
      " Iter:  75  Cost:  0.00175543944351375102996826171875\n",
      "-----------------------\n",
      " Iter:  76  Cost:  0.01178244967013597488403320312500\n",
      "-----------------------\n",
      " Iter:  77  Cost:  0.00193836097605526447296142578125\n",
      "-----------------------\n",
      " Iter:  78  Cost:  0.00224250741302967071533203125000\n",
      "-----------------------\n",
      " Iter:  79  Cost:  0.00831026770174503326416015625000\n",
      "-----------------------\n",
      " Iter:  80  Cost:  0.01372870430350303649902343750000\n",
      "-----------------------\n",
      " Iter:  81  Cost:  0.00692183058708906173706054687500\n",
      "-----------------------\n",
      " Iter:  82  Cost:  0.00952510163187980651855468750000\n",
      "-----------------------\n",
      " Iter:  83  Cost:  0.00597397796809673309326171875000\n",
      "-----------------------\n",
      " Iter:  84  Cost:  0.00085100933210924267768859863281\n",
      "-----------------------\n",
      " Iter:  85  Cost:  0.01266753673553466796875000000000\n",
      "-----------------------\n",
      " Iter:  86  Cost:  0.02476088702678680419921875000000\n",
      "-----------------------\n",
      " Iter:  87  Cost:  0.02110336720943450927734375000000\n",
      "-----------------------\n",
      " Iter:  88  Cost:  0.01017144322395324707031250000000\n",
      "-----------------------\n",
      " Iter:  89  Cost:  0.00958630815148353576660156250000\n",
      "-----------------------\n",
      " Iter:  90  Cost:  0.00384163530543446540832519531250\n",
      "-----------------------\n",
      " Iter:  91  Cost:  0.01020949613302946090698242187500\n",
      "-----------------------\n",
      " Iter:  92  Cost:  0.01304860599339008331298828125000\n",
      "-----------------------\n",
      " Iter:  93  Cost:  0.00744493026286363601684570312500\n",
      "-----------------------\n",
      " Iter:  94  Cost:  0.01851581037044525146484375000000\n",
      "-----------------------\n",
      " Iter:  95  Cost:  0.00191244983579963445663452148438\n",
      "-----------------------\n",
      " Iter:  96  Cost:  0.00230455771088600158691406250000\n",
      "-----------------------\n",
      " Iter:  97  Cost:  0.00621920637786388397216796875000\n",
      "-----------------------\n",
      " Iter:  98  Cost:  0.02013916149735450744628906250000\n",
      "-----------------------\n",
      " Iter:  99  Cost:  0.00353089021518826484680175781250\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# --- start session ---\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ti = train_images\n",
    "    tl = train_labels\n",
    "\n",
    "    for iter in range(num_epoch):\n",
    "        \n",
    "        # train\n",
    "        for current_batch_index in range(0,len(train_images),batch_size):\n",
    "            current_batch = train_images[current_batch_index:current_batch_index+batch_size,:,:,:]\n",
    "            current_label = train_labels[current_batch_index:current_batch_index+batch_size,:,:,:]\n",
    "            sess_results = sess.run([cost,auto_train],feed_dict={x:current_batch,y:current_label})\n",
    "            print(' Iter: ', iter, \" Cost:  %.32f\"% sess_results[0],end='\\r')\n",
    "        print('\\n-----------------------')\n",
    "        train_images,train_labels = shuffle(train_images,train_labels)\n",
    "\n",
    "        if iter % 2 == 0:\n",
    "            test_example =   train_images[:2,:,:,:]\n",
    "            test_example_gt = train_labels[:2,:,:,:]\n",
    "            sess_results = sess.run([layer10],feed_dict={x:test_example})\n",
    "\n",
    "            sess_results = sess_results[0][0,:,:,:]\n",
    "            test_example = test_example[0,:,:,:]\n",
    "            test_example_gt = test_example_gt[0,:,:,:]\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(np.squeeze(test_example),cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title('Original Image')\n",
    "            plt.savefig('train_change/'+str(iter)+\"a_Original_Image.png\")\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(np.squeeze(test_example_gt),cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title('Ground Truth Mask')\n",
    "            plt.savefig('train_change/'+str(iter)+\"b_Original_Mask.png\")\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(np.squeeze(sess_results),cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title('Generated Mask')\n",
    "            plt.savefig('train_change/'+str(iter)+\"c_Generated_Mask.png\")\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(np.multiply(np.squeeze(test_example),np.squeeze(test_example_gt)),cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Ground Truth Overlay\")\n",
    "            plt.savefig('train_change/'+str(iter)+\"d_Original_Image_Overlay.png\")\n",
    "\n",
    "            plt.figure()\n",
    "            plt.axis('off')\n",
    "            plt.imshow(np.multiply(np.squeeze(test_example),np.squeeze(sess_results)),cmap='gray')\n",
    "            plt.title(\"Generated Overlay\")\n",
    "            plt.savefig('train_change/'+str(iter)+\"e_Generated_Image_Overlay.png\")\n",
    "\n",
    "            plt.close('all')\n",
    "            \n",
    "        #get the same image\n",
    "        if iter % 2 == 0:\n",
    "            test_example =   ti[:2,:,:,:]\n",
    "            test_example_gt = tl[:2,:,:,:]\n",
    "            sess_results = sess.run([layer10],feed_dict={x:test_example})\n",
    "\n",
    "            sess_results = sess_results[0][0,:,:,:]\n",
    "            test_example = test_example[0,:,:,:]\n",
    "            test_example_gt = test_example_gt[0,:,:,:]\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(np.squeeze(test_example),cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title('Original Image')\n",
    "            plt.savefig('steady/'+str(iter)+\"a_Original_Image.png\")\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(np.squeeze(test_example_gt),cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title('Ground Truth Mask')\n",
    "            plt.savefig('steady/'+str(iter)+\"b_Original_Mask.png\")\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(np.squeeze(sess_results),cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title('Generated Mask')\n",
    "            plt.savefig('steady/'+str(iter)+\"c_Generated_Mask.png\")\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(np.multiply(np.squeeze(test_example),np.squeeze(test_example_gt)),cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Ground Truth Overlay\")\n",
    "            plt.savefig('steady/'+str(iter)+\"d_Original_Image_Overlay.png\")\n",
    "\n",
    "            plt.figure()\n",
    "            plt.axis('off')\n",
    "            plt.imshow(np.multiply(np.squeeze(test_example),np.squeeze(sess_results)),cmap='gray')\n",
    "            plt.title(\"Generated Overlay\")\n",
    "            plt.savefig('steady/'+str(iter)+\"e_Generated_Image_Overlay.png\")\n",
    "\n",
    "            plt.close('all')\n",
    "\n",
    "\n",
    "#     for data_index in range(0,len(train_images),batch_size):\n",
    "#         current_batch = train_images[current_batch_index:current_batch_index+batch_size,:,:,:]\n",
    "#         current_label = train_labels[current_batch_index:current_batch_index+batch_size,:,:,:]\n",
    "#         sess_results = sess.run(layer10,feed_dict={x:current_batch})\n",
    "\n",
    "#         plt.figure()\n",
    "#         plt.imshow(np.squeeze(current_batch[0,:,:,:]),cmap='gray')\n",
    "#         plt.axis('off')\n",
    "#         plt.title(str(data_index)+\"a_Original Image\")\n",
    "#         plt.savefig('gif/'+str(data_index)+\"a_Original_Image.png\")\n",
    "\n",
    "#         plt.figure()\n",
    "#         plt.imshow(np.squeeze(current_label[0,:,:,:]),cmap='gray')\n",
    "#         plt.axis('off')\n",
    "#         plt.title(str(data_index)+\"b_Original Mask\")\n",
    "#         plt.savefig('gif/'+str(data_index)+\"b_Original_Mask.png\")\n",
    "        \n",
    "#         plt.figure()\n",
    "#         plt.imshow(np.squeeze(sess_results[0,:,:,:]),cmap='gray')\n",
    "#         plt.axis('off')\n",
    "#         plt.title(str(data_index)+\"c_Generated Mask\")\n",
    "#         plt.savefig('gif/'+str(data_index)+\"c_Generated_Mask.png\")\n",
    "\n",
    "#         plt.figure()\n",
    "#         plt.imshow(np.multiply(np.squeeze(current_batch[0,:,:,:]),np.squeeze(current_label[0,:,:,:])),cmap='gray')\n",
    "#         plt.axis('off')\n",
    "#         plt.title(str(data_index)+\"d_Original Image Overlay\")\n",
    "#         plt.savefig('gif/'+str(data_index)+\"d_Original_Image_Overlay.png\")\n",
    "       \n",
    "#         plt.figure()\n",
    "#         plt.imshow(np.multiply(np.squeeze(current_batch[0,:,:,:]),np.squeeze(sess_results[0,:,:,:])),cmap='gray')\n",
    "#         plt.axis('off')\n",
    "#         plt.title(str(data_index)+\"e_Generated Image Overlay\")\n",
    "#         plt.savefig('gif/'+str(data_index)+\"e_Generated_Image_Overlay.png\")\n",
    "\n",
    "#         plt.close('all')\n",
    "\n",
    "\n",
    "# -- end code --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
